{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terms for Probability Distribution\n",
    "확률분포에 대해 알아보기 전에, 먼저 용어들을 제대로 정리하고, 이해한 후에 넘어가도록 하자. 앞으로 자주 마주칠 단어로는 Marginal distribution, joint distribution, conditional distribution이 있다. 이들은 다음과 같은 식들로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Joint Probability Distribution<br  />\n",
    "$P(A, B) = P(A \\cap B)$: 확률적으로 보면 event A와 event B가 동시에 일어날 확률이다. 확률분포에서 봤을 때 joint distribution은 A와 B라는 random variable의 확률분포이다. \n",
    "* Conditional Probability Distribution<br  />\n",
    "$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$: 확률적으로 보면 event B가 일어난 후 event A가 일어날 확률이다. 확률분포에서 봤을 때 conditional distribution은 부분집합의 확률분포라고 볼 수 있다. 즉, B에 포함된 A라는 부분집합의 확률분포인 것이다.<br  />\n",
    "참고로 conditional distribution과 joint distribution을 연관지어 생각할 수 있고 이는 Baye's rule의 기초가 된다. $P(A, B) = P(A|B)P(B) = P(B|A)P(A) = P(B, A)$\n",
    "* Marginal Probability Distribution<br  />\n",
    "$P(B) = \\sum_{B} P(A, B) = \\sum_{B} P(A|B)P(B)$: 확률적으로 보면 event A가 일어날 확률은 임의의 event B가 일어난 후 event A가 일어날 확률의 총 합과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "Machine Learning을 할 때 일반적으로 관측된 Data, training sample들로부터 regression이나 classification과 같은 목적에 부합하는 Model을 설계한다.\n",
    "\n",
    "확률적인 관점에서 생각해보면 관측된 data들은 진짜 data들의 distribution인 임의의 확률분포로부터 random하게 sampling된 data라고 가정할 수 있다. 진짜 data들의 분포는 $P(x)$, data들이 분류될 수 있는 class들의 분포는 $P(c)$, prior distribution으로 표현 가능하다. 또한, class에 포함된 data의 분포는 $P(x|c)$ 즉 관측된 data가 특정 class에 포함될 conditional distribution이다. 이는 machine learning에서 가장 중요한 개념 중 하나인 likelihood와 연관지어 생각해볼 수 있다. likelihood는 특정 class에 우리가 관측한 data가 얼마나 들어갈 수 있는지에 대한 정보이다. 따라서 class에 data가 포함될 확률인 $P(x|c)$에 비례하고, likelihood는 $L(\\theta|x)$로 표현한다. 이 때 $\\theta$는 class를 나타내는 확률 분포 parameter이며 likelihood를 최대화 하는 과정은 그와 비례하는 값인 $P(x|c)$를 최대화하는 과정과 동일하다. $P(c|x)$는 posterior distribution으로써 data가 들어왔을 때 특정 class에 매핑되는 확률 분포이다.\n",
    "\n",
    "딥러닝의 목표는 $P(x), P(c), P(x,c)$와 같은 진짜 data들의 분포 혹은 data가 어떤 class에 들어가는지에 대한 분포인 $P(c|x)$를 알아내는 것이다. 어떤 data가 특정 class에 들어가는 확률에 대해 알고 싶으면 $P(x|\\mu)$를 알아내야 한다. 여기서 $\\mu$는 확률 분포의 parameter이고 특정 class에 속할 확률로 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 쉬운 예로 동전을 던져서 앞면과 뒷면이 나올 확률을 구해보자. 앞면 혹은 뒷면인 것은 random variable $x=\\{0, 1\\}$로 볼 수 있고, 각각이 나올 확률은 확률 분포의 parameter로 볼 수 있다. 이를 수식으로 표현하면 다음과 같다.\n",
    "$$P(x|\\mu)=\\mu^x(1-\\mu)^{1-x}$$\n",
    "우리는 주어진 data로부터 확률 분포의 parameter $\\mu$를 알아내야 한다. 동전을 던져서 나온 data가 앞면 1번, 뒷면 1번이라고 뒀을 때, 앞면이 나올 확률은 직관적으로 봤을 때 0.5이다. 한 번 시행할 때의 확률은 위에서 본 식과 같기 때문에 총 두 번에 걸쳐 앞면과 뒷면이 한 번씩 나온 확률은, 이들이 독립시행이기 때문에 각각 곱하여서\n",
    "$$P(H1T1|\\mu)=\\mu (1-\\mu)$$\n",
    "위처럼 표현할 수 있고, 이를 parameter $\\mu$에 대한 그래프로 그려보면 0과 1사이에서 최댓값을 가질 때가 $\\mu=0.5$일 때임을 알 수 있다. 즉, 우리가 관측한 data를 가장 잘 설명할 수 있는 앞면이 나올 확률 분포에 대한 parameter값이 0.5라는 것이고 이는 우리의 직관과 일치한다. 이러한 방식으로 관측된 data를 설명할 수 있는 확률 분포를 찾는 것을 Maximum Likelihood Estimation, MLE라고 부르고 앞선 예에서 동전을 던졌을 때 앞면이 나올 확률을 특정 값으로 가정하고(가설), 그 값을 변화시키면서 어떤 가설이 가장 관측된 data를 잘 설명할 수 있는지 찾는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝에서 사용하는 또 다른 방법으로는 Maximum a Posterior, MAP가 있다. 이는 Posterior distribution을 최대화하는 과정이다. 이를 제대로 이해하기 위해서는 prior distribution, posterior distribution과 Baye's rule에 대한 이해가 필요하다. 우선 prior distribution의 경우 위키백과에서는 다음과 같이 설명한다. \"In Bayesian statistical inference, a prior probability distribution, often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account.\" 즉, data를 관측하기 전에 예상할 수 있는 data의 확률 분포이다. 예를 들어 우리는 동전 던지기에서 앞면이 나올 확률은 0.5로 알고 있다. 이처럼 관측을 하지 않았지만 마땅히 그럴 것이라고 예상되는 확률 분포가 prior distribution이다. Posterior distribution의 경우 위키백과에서 \"In Bayesian statistics, the posterior probability of a random event or an uncertain proposition is the conditional probability that is assigned after the relevant evidence or background is taken into account.\"와 같이 설명한다. 즉, 우리가 알고 있는 정보를 활용하여 구할 수 있는 conditional probability라는 것이다. 예를 들어서, 동전 던지기 100번을 할 때 60번의 앞면이 나왔을 때 동전을 던졌을 때 앞면이 나올 확률은 $P(T|E)$로 표현된다. $T$는 우리가 구하고자 하는 확률이고(가설), $E$는 관측된 data(증거)이다. Baye's rule은 이러한 posterior와 prior의 관계를 표현한 식으로 다음과 같이 정리할 수 있다.\n",
    "$$P(T|E) = \\frac{P(E\\cap T)}{P(E)} = \\frac{P(E|T)P(T)}{P(E)}$$\n",
    "가설 T에 특정 가정을 대입하고 그에 대한 확률을 계산하는 것인데, T=0.5라고 가정을 하면\n",
    "$$P(T=0.5|E=0.6)=\\frac{P(E=0.6|T=0.5)P(T=0.5)}{P(E=0.6)}$$\n",
    "처럼 계산할 수 있는데 여기서 우변 분자의 첫 째항은 앞서 구해보았던 likelihood로 구할 수 있고, 우변의 분모는 관측된 data이기 때문에 상수로 표현되기 때문에 prior distribution(이번에는 $T=0.5$라고 가정한)만 주어진다면 posterior를 구할 수 있게 되는 것이다. 여기에서, 0.5라고 가정하였던 prior distribution을 변수 $x$로 가정하면, posterior은 $x$에 대한 함수가 되어 $x$의 변화에 따른 최대값을 구할 수 있게 되고, 이러한 일련의 과정으로 posterior를 구하는 것이 MAP이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:msh]",
   "language": "python",
   "name": "conda-env-msh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
