{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATALOADER\n",
    "\n",
    "1. Make dataset, the class component. It needs length of overall dataset and items composing data to initialize.\n",
    "    - __init__ property is necessary for defining any kinds of class component and the variables used to define this property are data items\n",
    "    - To set length of the dataset, define the __len__ property of the class\n",
    "    - To set items of the dataset, define the __getitem__ property of the class, this needs index to indicate the index of each data items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sample data\n",
    "n_samples = 28\n",
    "x_data = np.random.randn(n_samples, 1).flatten()\n",
    "eps = np.random.normal(0.0, 1.0, n_samples)\n",
    "y_data = 3.*np.sin(2.*x_data) + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class sampleDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # defining init property, variable x, y are used to make dataset's items\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total length of the dataset\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # The return values of the 'getitem' property used for dataloader: these are output values of dataset class\n",
    "        x_data = self.x\n",
    "        y_data = self.y\n",
    "        return x_data[idx], y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.sampleDataset at 0x1f0e1146470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset = sampleDataset(x_data, y_data)\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After making dataset, use DataLoader to load each items of dataset we defined on previous section. We can choose\n",
    "    - batch size: If total dataset length is 10,000 and batch_size is 1000, then we have total 10 batches each containing 1000 data.\n",
    "    - sampler: For undersampling or oversampling, or any other sampling with ratios.\n",
    "    - shuffle: To shuffle or not every batches in dataset while loading.\n",
    "    - etc...\n",
    "    for options.\n",
    "    \n",
    "If we divide dataset into mini-batch, each mini-batch contains items in this example, they are x_data and y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4 batch and each batch contains 7 number of data\n",
      "In batch 1 there are\n",
      "x data: tensor([-1.2445,  2.0414, -0.7364, -0.3928, -1.1348,  0.5417,  1.8872],\n",
      "       dtype=torch.float64)\n",
      "y_data: tensor([-1.3224, -3.4081, -3.3793, -1.6284, -3.1557,  3.3854, -1.9351],\n",
      "       dtype=torch.float64)\n",
      "In batch 2 there are\n",
      "x data: tensor([ 0.7863,  1.1698,  1.3797, -0.9800, -0.7384,  0.7144, -0.8483],\n",
      "       dtype=torch.float64)\n",
      "y_data: tensor([ 3.2183,  2.1055,  1.0005, -2.9727, -3.2439,  3.2780, -4.1728],\n",
      "       dtype=torch.float64)\n",
      "In batch 3 there are\n",
      "x data: tensor([-0.9447, -0.7057,  0.0877, -0.2223, -0.4308, -1.1246, -1.0773],\n",
      "       dtype=torch.float64)\n",
      "y_data: tensor([-3.1492, -4.4241,  0.8666, -2.1749, -2.6562, -0.6330, -2.4063],\n",
      "       dtype=torch.float64)\n",
      "In batch 4 there are\n",
      "x data: tensor([ 1.2376,  1.1711,  0.2226, -1.1322,  0.4147, -1.8268,  0.1072],\n",
      "       dtype=torch.float64)\n",
      "y_data: tensor([ 2.0179,  2.5381, -0.6607, -2.9606,  2.0488, -0.2267,  1.7169],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 7\n",
    "data_4batch = DataLoader(dataset=sample_dataset, batch_size=7)\n",
    "print(\"Total {} batch and each batch contains {} number of data\".format(n_samples//batch_size, batch_size))\n",
    "for idx, batch in enumerate(data_4batch):\n",
    "    print(\"In batch {} there are\".format((idx+1), ))\n",
    "    print(\"x data: {}\".format(batch[0]))\n",
    "    print(\"y_data: {}\".format(batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 7 batch and each batch contains 4 number of data\n",
      "In batch 1 there are\n",
      "x data: tensor([-1.2445,  2.0414, -0.7364, -0.3928], dtype=torch.float64)\n",
      "y_data: tensor([-1.3224, -3.4081, -3.3793, -1.6284], dtype=torch.float64)\n",
      "In batch 2 there are\n",
      "x data: tensor([-1.1348,  0.5417,  1.8872,  0.7863], dtype=torch.float64)\n",
      "y_data: tensor([-3.1557,  3.3854, -1.9351,  3.2183], dtype=torch.float64)\n",
      "In batch 3 there are\n",
      "x data: tensor([ 1.1698,  1.3797, -0.9800, -0.7384], dtype=torch.float64)\n",
      "y_data: tensor([ 2.1055,  1.0005, -2.9727, -3.2439], dtype=torch.float64)\n",
      "In batch 4 there are\n",
      "x data: tensor([ 0.7144, -0.8483, -0.9447, -0.7057], dtype=torch.float64)\n",
      "y_data: tensor([ 3.2780, -4.1728, -3.1492, -4.4241], dtype=torch.float64)\n",
      "In batch 5 there are\n",
      "x data: tensor([ 0.0877, -0.2223, -0.4308, -1.1246], dtype=torch.float64)\n",
      "y_data: tensor([ 0.8666, -2.1749, -2.6562, -0.6330], dtype=torch.float64)\n",
      "In batch 6 there are\n",
      "x data: tensor([-1.0773,  1.2376,  1.1711,  0.2226], dtype=torch.float64)\n",
      "y_data: tensor([-2.4063,  2.0179,  2.5381, -0.6607], dtype=torch.float64)\n",
      "In batch 7 there are\n",
      "x data: tensor([-1.1322,  0.4147, -1.8268,  0.1072], dtype=torch.float64)\n",
      "y_data: tensor([-2.9606,  2.0488, -0.2267,  1.7169], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "data_7batch = DataLoader(dataset=sample_dataset, batch_size=batch_size)\n",
    "print(\"Total {} batch and each batch contains {} number of data\".format(n_samples//batch_size, batch_size))\n",
    "for idx, batch in enumerate(data_7batch):\n",
    "    print(\"In batch {} there are\".format((idx+1), ))\n",
    "    print(\"x data: {}\".format(batch[0]))\n",
    "    print(\"y_data: {}\".format(batch[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "In deep learning **Batch** size is quite important concept. This is because of the training method of deep learning. Mostly we use **Gradient Descent** method that updata learning parameters through reverse direction of loss function's gradient to decrease the loss of the model.\n",
    "\n",
    "Let's suppose that we have training set that have 100,000 data. When we use gradient descent in this dataset, we have to calculate loss function of 100,000 data each time we go through the iteration. This could cause enormous amount of calculations. So researchers suggested **Stochastic Gradient Descent** method that use only one example for calculating loss function of each iteration. But you can simply expect using 1 data among 100,000 data will not good at training since too small number of data can't cause significant difference to updating parameters.\n",
    "\n",
    "Improved version of stochastic gradient descent method is **Mini-Batch Stochastic Gradient Descent(SGD)** method which is mostly used in deep learning process. In SGD method, we divide total dataset into mini-batch and model only calculate gradients about each mini-batch at each iteration. The bigger batch size will cause more accurate gradient but increase in calculation of each iteration. But if we use multi GPU or TPU for calculation, we can reduce the training time with their parallel calculation ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing model with pytorch is quite easy. We can use many functions such as <code>nn.Sequential</code> or <code>nn.ModuleList</code>. Tough part is attaching the dataloader and model part without any conflicts. For example, let's make simple MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "def MLP(hidden_size):\n",
    "    layer_list = list()\n",
    "    layer_list.append(nn.Linear(in_features=1, out_features=hidden_size))\n",
    "    layer_list.append(nn.ReLU())\n",
    "    layer_list.append(nn.Linear(in_features=hidden_size, out_features=1))\n",
    "    model = nn.Sequential(*layer_list)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=200, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(200)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), 0.005)\n",
    "criteria = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4]) torch.Size([4])\n",
      "torch.Size([4, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# dataset with 7 batches, each contains 4 data items\n",
    "for i, batch in enumerate(data_7batch):\n",
    "    x_batch = (batch[0].clone().detach().requires_grad_(True))\n",
    "    y_batch = (batch[1].clone().detach().requires_grad_(True))\n",
    "    \n",
    "    x_batch_reform = x_batch.view(-1, 1)\n",
    "    y_batch_reform = y_batch.view(-1, 1)\n",
    "    \n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    print(x_batch_reform.shape, y_batch_reform.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the two data form, x_batch or x_batch_reform can be used for training of our model?\n",
    "\n",
    "x_batch data has size of [4] and x_batch_reform data has size of [4,1]. Our model start with <code>nn.Linear</code> layer with <code>in_features=1</code>.\n",
    "$$H = XW+B, \\{W\\in \\mathbb{R}^{1\\times 200}, B \\in \\mathbb{R}^{200}, h \\in \\mathbb{R}^{N \\times 200}\\}$$\n",
    "The value $N$ in above equation is batch size of the dataset. It means that we should make input data into tensor with the size of **batch size $\\times$ in_features**. Meanwhile, out_featuer of the model's last layer should be same with the dimension of the values that we predict. For example, if we want to predict two values, we should set out feature of the last layer two, or if we want to predict three values, we should set out feature of the last layer three.\n",
    "\n",
    "Below codes are example of failure and success for running model with input data dimension [4], [4,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# success, in feature of the first lyaer of MLP model is same with our input data dimension\n",
    "# dataset with 7 batches, each contains 4 data items\n",
    "for i, batch in enumerate(data_7batch):\n",
    "    x_batch_reform = (batch[0].clone().detach().requires_grad_(True)).view(-1, 1)\n",
    "    y_batch_reform = (batch[1].clone().detach().requires_grad_(True)).view(-1, 1)\n",
    "    y_pred = model(x_batch_reform)\n",
    "\n",
    "    print(x_batch_reform.shape, y_batch_reform.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 4], m2: [1 x 200] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:961",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-00cd53e99d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msh\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msh\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msh\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msh\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\msh\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 4], m2: [1 x 200] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:961"
     ]
    }
   ],
   "source": [
    "# failure since dimension is not matched\n",
    "# dataset with 7 batches, each contains 4 data items\n",
    "for i, batch in enumerate(data_7batch):\n",
    "    x_batch = (batch[0].clone().detach().requires_grad_(True))\n",
    "    y_batch = (batch[1].clone().detach().requires_grad_(True))\n",
    "    y_pred = model(x_batch)\n",
    "\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:msh]",
   "language": "python",
   "name": "conda-env-msh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
